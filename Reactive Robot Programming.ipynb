{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reactive Robot Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will develop a library for reactive programming of the Aldebaran Nao robot. We will first let the robot look around for red balls, and make the robot point towards red balls which are within target range.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the contents of Reactive Extensions (rx), naoqi and the Reactive Extensions for Qi libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rx import *\n",
    "from naoqi import *\n",
    "import datetime\n",
    "from rx.subjects import Subject\n",
    "from threading import Thread\n",
    "import sys, time\n",
    "\n",
    "Stream = Observable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be connecting to a real Nao, for which we need to configure the IP address. Change the line below to match the IP address of your Nao robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nao_address = \"tcp://192.168.11.162:9559\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Qi framework to create a session for this robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session = qi.Session(nao_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To debug our code, we can print the last value. An easy way to print a value in Rx is to subscribe a print function to a stream. In Python 2 however we cannot directly use print as a function. We can however import a print function from the future library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bridging naoqi and Reactive Extensions\n",
    "\n",
    "The Qi framework provides us with some features for responding to memory events. ReactiveX has its own model for reactive programming. To bridge Qi and Rx, we create a Subject.\n",
    "\n",
    "Because the subject has to continue monitoring the memory after it has been created, we run it in its own thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QiMemorySubject(Thread):\n",
    "    def __init__(self, field, session):\n",
    "        Thread.__init__(self)\n",
    "        self.session = session\n",
    "        self.field = field\n",
    "        self.stopped = False\n",
    "        self.subject = Subject()\n",
    "        \n",
    "    def run(self):\n",
    "        mem = self.session.service(\"ALMemory\")\n",
    "        self.subscriber = mem.subscriber(self.field)\n",
    "        self.signal = self.subscriber.signal.connect(self.subject.on_next)\n",
    "        while not self.stopped:\n",
    "            time.sleep(1)\n",
    "        \n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        self.subscriber.signal.disconnect(self.signal)\n",
    "        print(\"Stopping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listening for a red ball\n",
    "\n",
    "We can now easily create subjects listening to various sensors of the robot, such as red balls and blobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RedBallSubject(QiMemorySubject):\n",
    "    def __init__(self, session):\n",
    "        QiMemorySubject.__init__(self, \"redBallDetected\", session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then start a red ball subject which uses the camera of Nao to look for red balls. Because we designed the red ball subject class to extend the Qi memory subject, and Qi memory subject runs in its own thread, we have to start the thread to start listening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redBallThread = RedBallSubject(session)\n",
    "redBallThread.daemon = True\n",
    "redBallThread.start()  # start the thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nao should now be listening for red balls. To check if it is actually working, we can sample the subject. Because we do not want to spam our notebook, we set up a special stream which only returns the first red ball seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "firstRedBall = redBallThread.subject.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's debug our first red ball stream using print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "firstRedBallSub = firstRedBall.subscribe(lambda red_ball: print(\"Red ball spotted: \" + str(red_ball)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In robotics, printing values is used mainly for quick testing and debugging. A production program running on an autonomous robot should contain almost no calls to print, as there is no-one controlling the robot who would be interested in reading those prints. \n",
    "\n",
    "Before we go on, let's dispose of our temporary print function. We can do this by disposing the subscription we made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "firstRedBallSub.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "RedBallDetection gives us a list containing the following values:\n",
    "* Timestamp (seconds, microseconds)\n",
    "* Ball info (center x, center y, size x, size y, all in radians)\n",
    "* Camera pose in torso frame\n",
    "* Camera pose in robot frame (average of both feet)\n",
    "* Camera id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we create a class called Ball to hold the ball information. We overwrite the string magic method for pretty printing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ball():\n",
    "    def __init__(self, x, y, width, height):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "    \n",
    "    def __str__(self):\n",
    "        template = \"Location of ball: (center x: %s rad, center y: %s rad, size x: %s rad, size y: %s rad)\"\n",
    "        return template % (self.x, self.y, self.width, self.height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a map operator we can get just the information we need, e.g. the ball info. We use our ball class for converting the list to an object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ball = redBallThread.subject.map(lambda ballInfo: Ball(*(ballInfo[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We debug the ball stream using a print subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "firstBall = ball.first()\n",
    "\n",
    "firstBallSubscription = firstBall.subscribe(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid too much spam, let's dispose of our print function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "firstBallSubscription.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ball detector produces a lot of events. For our use case we can instead sample the stream to reduce the amount of events which we need to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ballSamples = ball.sample(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out the distance between the robot and the ball, we have to do some simple trigonometry. We know that the formula for an angle $\\theta$ given the opposite side $A$ and adjacent side $B$ is given by the tangent.\n",
    "\n",
    "$tan(\\theta)=\\dfrac{A}{B}$\n",
    "\n",
    "In our case, we are given the angle $\\theta$. Given a $size$ which is half the height or width of the ball, i.e. the radius, we can calculate the $distance$ to the ball by using the tangent function:\n",
    "\n",
    "$distance = \\dfrac{\\dfrac{size}{2}}{tan(\\theta)} = \\dfrac{size}{2*tan(\\theta)}$\n",
    "\n",
    "In Python this is implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import tan \n",
    "\n",
    "def distance_to_ball(ball_size, angle):\n",
    "    return ball_size / (2 * tan(angle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this for a ball with a size of 4 cm, with a reported angle of 45 degrees. If we fill these values into our formula we get:\n",
    "\n",
    "$distance = \\dfrac{4 cm}{2*tan(45^{\\circ})}=2cm$\n",
    "\n",
    "Note that the Python tangent function by default takes as parameter the angle in radians and not in degrees. Hence instead of using 45 degrees, we use $\\pi/4 rad$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import pi, radians\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(range(1,46), [distance_to_ball(5, x) for x in [radians(l) for l in range(1,46)]])\n",
    "\n",
    "plt.xlabel('Angle (degree)')\n",
    "plt.ylabel('Distance (cm)')\n",
    "plt.title('Distance according to angle')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the accuracy of the distance measurement we will use the average of the observed width and height. We write a function called dist2 which performs this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist2(width, height): \n",
    "    return (1/4.) * (size/tan(width) + size/tan(height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we write a function ball_distance which uses dist2 for calculating the distance to the ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ball_distance(ball): \n",
    "    return dist2(ball.width, ball.height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our new distance function, let's create a stream which gives us the distance to the ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance = ballSamples.map(ball_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test our stream using print:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-e993d31b90f1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-e993d31b90f1>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    firstRedBallDistanceSub = redBallDistance.first().subscribe(lambda distance: print(\"Distance: %s cm\" % (distance)))\u001b[0m\n\u001b[1;37m                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "firstRedBallDistanceSub = distance.first().subscribe(lambda distance: print(\"Distance: %s cm\" % (distance)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's dispose of our print function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "firstRedBallDistanceSub.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling LEDs based on ball distance\n",
    "We can now calculate the distance to the ball. We can make the robot react differently depending on this distance. For example, let's change the light color of Nao's eyes based on the distance of the ball.\n",
    "\n",
    "We use the ALLeds module for controlling the LEDs of the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leds = session.service(\"ALLeds\")\n",
    "leds.off(\"FaceLeds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we write a function to determine the brightness of the LEDs based on distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def brightness(distance):\n",
    "    if distance > 20:\n",
    "        return 0\n",
    "    elif distance > 5:\n",
    "        return (-(distance-5)/15.) + 1\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we write a function which sets the LED brightness based on the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def led_brightness(intensity):\n",
    "    leds.setIntensity(\"RightFaceLedsRed\", intensity)\n",
    "    leds.setIntensity(\"LeftFaceLedsRed\", intensity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrote the above as two separate functions so we can test the intensity function separately from the robot. Let's plot our intensity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(range(0,31), [get_intensity(x) for x in range(0,31)])\n",
    "\n",
    "plt.xlabel('distance (cm)')\n",
    "plt.ylabel('intensity')\n",
    "plt.title('LED intensity over distance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now subscribe our brightness function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ballSamplesSub = ballSamples.subscribe(led_brightness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can dispose of our subscription if we don't want our brightness function to remain active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ballSamplesSub.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking the ball\n",
    "Aldebaran offers a red ball tracker. We will make our own using reactive programming. This tracker gives us more flexibility than the build in tracker, for example we can make the robot transition from looking at the ball to pointing at it. We will still use some functionality of the original tracker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracker = session.service(\"ALTracker\")\n",
    "tracker.registerTarget(\"RedBall\", 0.04)\n",
    "tracker.track(\"RedBall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the robot in the crouching position and get some sensor readings which we later need to reset the arm after tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posture = session.service(\"ALRobotPosture\")\n",
    "posture.goToPosture(\"Crouch\", 1.0)\n",
    "\n",
    "motion = session.service(\"ALMotion\")\n",
    "sensor_angles = motion.getAngles([\"LArm\"], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a stream for detecting whether balls are close or far using a map operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def point_or_track(close):\n",
    "    if close:\n",
    "        target = tracker.getTargetPosition(0)\n",
    "        tracker.pointAt(\"LArm\", target, 0, 0.5)\n",
    "    else:\n",
    "        tracker.setMode(\"Head\")\n",
    "        motion.setAngles([\"LArm\"], sensor_angles, 0.2)\n",
    "        \n",
    "pointRangeBalls = redBallDistanceSamples.map(lambda distance: distance < 20)\n",
    "pointRangeBallsSub = pointRangeBalls.subscribe(point_or_track)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing our behavior we can dispose of the subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pointRangeBallsSub.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to move towards grabbing the ball if it is within reach. Let's try a naive implementation which closes the hand if the ball is very close, and opens it otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def open_or_close(graspable):\n",
    "    if graspable:\n",
    "        motion.closeHand('LHand')\n",
    "    else:\n",
    "        motion.openHand('LHand')\n",
    "\n",
    "graspRangeBalls = redBallDistanceSamples.map(lambda distance: distance < 15)\n",
    "graspRangeBallsSub = graspRangeBalls.subscribe(open_or_close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we should dispose after testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graspRangeBallsSub.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining which effector to use\n",
    "\n",
    "We want to track objects to the left with the left effector and objects to the right with the right effector. To determine which effector to use, we take the sum of the angle of the head and the angle in the camera frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QiPullingMemorySubject(Thread):\n",
    "    def __init__(self, field, session, pull_rate):\n",
    "        Thread.__init__(self)\n",
    "        self.session = session\n",
    "        self.field = field\n",
    "        self.pull_rate = pull_rate / 1000.0\n",
    "        self.stopped = False\n",
    "        self.subject = Subject()\n",
    "        \n",
    "    def run(self):\n",
    "        mem = self.session.service(\"ALMemory\")\n",
    "        #latched_data = 0\n",
    "        while not self.stopped:\n",
    "            data = mem.getData(self.field)\n",
    "            \n",
    "            #if data < latched_data - 0.02 or data > latched_data + 0.02:\n",
    "            self.subject.on_next(data)\n",
    "            #    latched_data = data\n",
    "            time.sleep(self.pull_rate)\n",
    "        \n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        print(\"Stopping\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HeadYawSubject(QiPullingMemorySubject):\n",
    "    def __init__(self, session):\n",
    "        QiPullingMemorySubject.__init__(self, \"Device/SubDeviceList/HeadYaw/Position/Sensor/Value\", session, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headYawThread = HeadYawSubject(session)\n",
    "headYawThread.daemon = True\n",
    "headYawThread.start()\n",
    "head_yaw = headYawThread.subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Example 2 specific\n",
    "## Functions\n",
    "# mapping ball to a pair containing its x angle and distance\n",
    "angle_dist_helper = lambda ball: (ball.x, dist2(ball.width, ball.height))\n",
    "# combining head_yaw with robot_angle\n",
    "combinator = lambda headYaw, ballAngle: (headYaw.value+ballAngle.value, \n",
    "                                         headYaw.timestamp-ballAngle.timestamp)\n",
    "recent = lambda pair: pair[1].total_seconds() < 1\n",
    "## CEP graph\n",
    "# distance to head and head & body\n",
    "head = distance.filter(lambda d: d >= 50)\n",
    "head_subscription = head.subscribe(head_tracker)\n",
    "head_body = distance.filter(lambda d: d >= 20 and d < 50)\n",
    "head_body_subscription = head_body.subscribe(head_body_tracker)\n",
    "# BallSamples to Camera angle time\n",
    "cam_angle_dist = ballSamples.map(angle_dist_helper)\n",
    "cam_angle_dist_filtered = cam_angle_dist.filter(lambda pair: pair[1] < 20)\n",
    "cam_angle = cam_angle_dist_filtered.map(lambda pair: pair[0])\n",
    "# product of object's camera angle and head yaw\n",
    "cam_angle_timestamped = cam_angle.timestamp()\n",
    "head_yaw_timestamped = head_yaw.timestamp()\n",
    "robot_angle_timestamped = Stream.combine_latest(head_yaw_timestamped, \n",
    "                                                cam_angle_timestamped, \n",
    "                                                combinator)\n",
    "robot_angle = robot_angle_timestamped.filter(recent)\n",
    "arm = robot_angle.map(lambda a: \"LArm\" if a[0] > 0 else \"RArm\")\n",
    "arm_subscription = arm.subscribe(arm_tracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TDM example\n",
    "\n",
    "We will now construct an example from the TDM paper. \n",
    "\n",
    "We want a robot which reacts to humans and collects objects in an environment. Reacting to the human means that the robot will initially greet the human and verbally respond to touching such as petting on the head. Objects will be small blue pluche balls. The robot collects these balls and bring them to a human, if present.\n",
    "\n",
    "To construct this behavior we will split it into small reactive behaviors, and then combine these behaviors to realize more advanced behavior. Let's start with finding the blue pluche balls.\n",
    "\n",
    "In the previous example we programmed the robot to track a red ball. We conveniently reused the red ball tracker which is part of the Naoqi framework. For other color balls the programming is a little bit more complicated, but still manageable.\n",
    "\n",
    "Before running the code below, make sure you ran the code fragments in the introduction for connecting to the robot and creating QiMemorySubject. You will also need to change the color properties of the object you want to detect. To find out the red, green, blue values for the color, you can use the Nao Monitor application to take a picture of the ball you want to track, and then set the values accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BlobDetectionSubject(QiMemorySubject):\n",
    "    def __init__(self, session):\n",
    "        QiMemorySubject.__init__(self, \"ALTracker/ColorBlobDetected\", session)\n",
    "        \n",
    "class BlueBlobDetectionSubject(BlobDetectionSubject):\n",
    "    def __init__(self, session):\n",
    "        BlobDetectionSubject.__init__(self, session)\n",
    "        blobDetection = session.service(\"ALColorBlobDetection\")\n",
    "        blobDetection.setColor(50, 210, 240, 20) # change these values to match the ball color\n",
    "        blobDetection.setObjectProperties(30, 0.04, \"Circle\")\n",
    "        blobDetection.subscribe(\"BlueBlob\", 500, 0)\n",
    "        \n",
    "class RedBlobDetectionSubject(BlobDetectionSubject):\n",
    "    def __init__(self, session):\n",
    "        BlobDetectionSubject.__init__(self, session)\n",
    "        blobDetection = session.service(\"ALColorBlobDetection\")\n",
    "        blobDetection.setColor(50, 194, 23, 50) # change these values to match the ball color\n",
    "        blobDetection.setObjectProperties(30, 0.04, \"Circle\")\n",
    "        blobDetection.subscribe(\"RedBlob\", 500, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate our blue blob detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blueBlobDetection = BlueBlobDetectionSubject(session)\n",
    "blueBlobDetection.daemon = True\n",
    "blueBlobDetection.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the red ball example, the robot will not actually start detecting objects until we instantiate a tracker, which is what we do now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracker = session.service(\"ALTracker\")\n",
    "tracker.trackEvent(\"ALTracker/ColorBlobDetected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the first value in the stream to test our blue blob detection. First we select the first message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "firstBlueBlob = blueBlobDetection.subject.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we subscribe our print function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "firstBlueBlobSub = firstBlueBlob.subscribe(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it worked well, we can dispose of our print function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "firstBlueBlobSub.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to write a function which compares the objects returned by the blob stream. The format differs from the red ball format.\n",
    "* Target position in the torso frame, as a Position6D\n",
    "* Target position in the robot frame, as a Position6D\n",
    "* Timestamp in seconds and in microseconds\n",
    "* Effector which should be used for tracking (unused)\n",
    "* Threshold (in radians) to avoid head oscillation (unused)\n",
    "\n",
    "A Position6D contains three translations (in meters) and three rotations (in radians). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now written the logic required to detect blue blobs. However we would like this program to work in a world where there are multiple blue blobs, hence we somehow have to split the detected blobs if multiple are found. We can do this using a group by operation. This operation groups the elements in a stream based on a comparator. \n",
    "\n",
    "In Python we can overload the equals operator to accomplish this, however we first need to wrap the blob into a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "class Position6D():\n",
    "    def __init__(self, values, similarity_threshold=0.1):\n",
    "        self.robot_pos = values[0]\n",
    "        self.x, self.y, self.z = self.robot_pos[0:3]\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        \n",
    "    def distance(self, x_p=0, y_p=0, z_p=0):\n",
    "        sqrdiff = lambda a, b: pow(abs(a-b), 2)\n",
    "        x, y, z = self.x, self.y, self.z\n",
    "        return sqrt(sqrdiff(x, x_p) + sqrdiff(y, y_p) + sqrdiff(z, z_p))\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        x_p, y_p, z_p = other.x, other.y, other.z\n",
    "        return self.distance({'x': x_p, 'y': y_p, 'z': z_p}) <= self.similarity_threshold\n",
    "\n",
    "    \n",
    "class Blob():\n",
    "    def __init__(self, values):\n",
    "        self.robot_pos = Position6D(values)\n",
    "        \n",
    "    def distance(self):\n",
    "        return self.robot_pos.distance()\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return self.robot_pos == other.robot_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threading.active_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threading.current_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threading.enumerate()[0].stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threading.enumerate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FaceDetectionSubject(QiMemorySubject):\n",
    "    def __init__(self, session):\n",
    "        QiMemorySubject.__init__(self, \"FaceDetected\", session)\n",
    "        faceDetection = session.service(\"ALFaceDetection\")\n",
    "        faceDetection.subscribe(\"FaceDetected\", 500, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faceDetection = FaceDetectionSubject(session)\n",
    "faceDetection.daemon = True\n",
    "faceDetection.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def time_stamp_dict(data):\n",
    "    return {\n",
    "        'seconds': data[0],\n",
    "        'microseconds': data[1]\n",
    "    }\n",
    "\n",
    "def shape_info_dict(data):\n",
    "    ''' info of the face shape from camera angles in radians '''\n",
    "    if data != 0:\n",
    "        return {\n",
    "            'alpha': data[1],\n",
    "            'beta': data[2],\n",
    "            'size_x': data[3],\n",
    "            'size_y': data[4]\n",
    "        }\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def extra_info_dict(data):\n",
    "    return {\n",
    "        'face_id': data[0],\n",
    "        'score_recognition': data[1],\n",
    "        'face_label': data[2]\n",
    "    }\n",
    "\n",
    "def face_info_dict(data):\n",
    "    return {\n",
    "        'shape_info': shape_info_dict(data[0]),\n",
    "        'extra_info': [extra_info_dict(extra) for extra in data[1:len(data)-1]]\n",
    "    }\n",
    "\n",
    "class RecognitionInfo(Enum):\n",
    "    nothing_new = 0\n",
    "    one_face = 2\n",
    "    several_faces = 3\n",
    "    learn_face_suggestion = 4\n",
    "\n",
    "def recognition_info_dict(data):\n",
    "    return {\n",
    "        'status': RecognitionInfo(data[0]),\n",
    "        'labels': None if len(data) == 0 or data[0] == 4 else data[1]\n",
    "        # labels if there are any\n",
    "    }\n",
    "\n",
    "def face_data_dict(data):\n",
    "    return {\n",
    "        'face_info': [face_info_dict(face) for face in data[0:len(data)-1]],\n",
    "        'recognition_info': recognition_info_dict(data[len(data)-1]) if data[len(data)-1] != [] else None\n",
    "    }\n",
    "\n",
    "def face_detected_dict(data):\n",
    "    if len(data) >= 2:\n",
    "        return {\n",
    "            'time_stamp': time_stamp_dict(data[0]),\n",
    "            'face_data': face_data_dict(data[1])\n",
    "        }\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faceDetectionSamples = faceDetection.subject.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def face_distance(angle_width, angle_height, width=14.9, height=20.05):\n",
    "    return (distance(width, angle_width) + distance(height, angle_height)) / 2\n",
    "\n",
    "def detect_face_distance(face, width=14.9, height=20.05):\n",
    "    if face == None:\n",
    "        return -1\n",
    "    shape_info = face['face_data']['face_info'][0]['shape_info']\n",
    "    return face_distance(shape_info['size_x'], shape_info['size_y'], 13, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blueBlobDetectionSamples = blueBlobDetection.subject.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blueBlobDetectionWithDistance = blueBlobDetectionSamples.map(lambda item: (\"blue_blob\", 50 * (Blob(item).distance())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blueBlobDetectionWithDistanceSub = blueBlobDetectionWithDistance.subscribe(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blueBlobDetectionWithDistanceSub.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faceDetectionSamplesMapped = faceDetectionSamples.map(lambda x, y: face_detected_dict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "faceDetectionSamplesMappedSub = faceDetectionSamplesMapped.subscribe(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faceDetectionSamplesMappedSub.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faceDetectionSamplesMappedDistance = faceDetectionSamplesMapped.map(lambda face: (\"face\", detect_face_distance(face)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "faceDetectionSamplesMappedDistanceSub = faceDetectionSamplesMappedDistance.subscribe(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "faceDetectionSamplesMappedDistanceSub.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latestFaceAndBall = Observable.combine_latest(faceDetectionSamplesMappedDistance, blueBlobDetectionWithDistance, lambda face, blob: (face, blob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latestFaceAndBallSub = latestFaceAndBall.subscribe(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latestFaceAndBallSub.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def closest_face_or_blob(face, blob):\n",
    "    if face[1] == -1:\n",
    "        return blob\n",
    "    elif blob[1] == -1:\n",
    "        return face\n",
    "    else:\n",
    "        if face[1] > blob[1]:\n",
    "            return blob\n",
    "        else:\n",
    "            return face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Paper example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def head_tracker(distance): print(\"head\")\n",
    "def head_body_tracker(distance): print(\"head and body\")\n",
    "def arm_tracker(arm): print(arm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
